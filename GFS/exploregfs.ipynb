{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_date = '2021-01-01'\n",
    "last_date  = '2022-12-31'\n",
    "\n",
    "lonmin,lonmax = 360-90,360-69\n",
    "latmin,latmax = -40,-15\n",
    "\n",
    "fnlgfs_dictionary = {\n",
    "    'Downward_Short-Wave_Radiation_Flux_surface':'dswrfsfc',\n",
    "    'Downward_Long-Wave_Radp_Flux_surface':'dlwrfsfc',\n",
    "    'Upward_Long-Wave_Radp_Flux_surface':'ulwrfsfc',\n",
    "    'Upward_Short-Wave_Radiation_Flux_surface':'uswrfsfc',\n",
    "    'u-component_of_wind_height_above_ground':'ugrd10m',\n",
    "    'v-component_of_wind_height_above_ground':'vgrd10m',\n",
    "    'Precipitation_rate_surface':'pratesfc',\n",
    "    'Relative_humidity_height_above_ground':'rh2m',\n",
    "    'Temperature_height_above_ground':'tmp2m',\n",
    "}\n",
    "\n",
    "flux_variables = [\n",
    "    'Downward_Short-Wave_Radiation_Flux_surface',\n",
    "    'Downward_Long-Wave_Radp_Flux_surface',\n",
    "    'Upward_Short-Wave_Radiation_Flux_surface',\n",
    "    'Upward_Long-Wave_Radp_Flux_surface'\n",
    "    ]\n",
    "    \n",
    "bulk_variables   = [\n",
    "    'u-component_of_wind_height_above_ground',\n",
    "    'v-component_of_wind_height_above_ground',\n",
    "    'Precipitation_rate_surface',\n",
    "    'Relative_humidity_height_above_ground',\n",
    "    'Temperature_height_above_ground',\n",
    "    ]\n",
    "\n",
    "gfs_variables = [\n",
    "    'vgrd10m',\n",
    "    'ugrd10m',\n",
    "    'tmp2m',\n",
    "    'rh2m',\n",
    "    'pratesfc',\n",
    "    'dswrfsfc',\n",
    "    'dlwrfsfc',\n",
    "    'uswrfsfc',\n",
    "    'ulwrfsfc'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### GDAS/FNL Hindcast (GFS Archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GDASFNL_filename(idate, ftype):\n",
    "    \"\"\"\n",
    "    This function builds the url for the openDAP webservice of\n",
    "    the GDAS/FNL GFS archive dataset.\n",
    "\n",
    "    Args:\n",
    "        idate (str): date string as (%Y-%m-%d %H:%M:%S) format\n",
    "        ftype (str): flux or bulk dataset\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if ftype not flux or bulk\n",
    "\n",
    "    Returns:\n",
    "        str: opendap url\n",
    "    \"\"\"\n",
    "    date    = pd.to_datetime(idate)\n",
    "    year    = date.strftime('%Y')\n",
    "    yrmonth = date.strftime('%Y%m')\n",
    "    ftime   = date.strftime('%Y%m%d%H')\n",
    "    if ftype == 'flux':\n",
    "        url     = 'https://rda.ucar.edu/thredds/dodsC/files/g/ds084.4/'+year+'/'+yrmonth+'/gdas1.sflux.'+ftime+'.f00.grib2'\n",
    "    elif ftype == 'bulk':\n",
    "        url     = 'https://rda.ucar.edu/thredds/dodsC/files/g/ds083.3/'+year+'/'+yrmonth+'/gdas1.fnl0p25.'+ftime+'.f00.grib2'\n",
    "    else:\n",
    "        raise ValueError('ftype can only be \"flux\" or \"bulk\"')\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_GDASFNL_bulks(idate, lonmin, lonmax, latmin, latmax, variables):\n",
    "    \"\"\"\n",
    "    Given a date and a collection of variables this function grabs\n",
    "    the GFS/FNL data from the opendap service\n",
    "\n",
    "    Args:\n",
    "        idate (_type_): _description_\n",
    "        variables (_type_, optional): _description_. Defaults to bulk_variables.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # NCEP GDAS/FNL 0.25 Degree Global Tropospheric Analyses and Forecast Grids\n",
    "    bulkfiles = [get_GDASFNL_filename(idate+hour, 'bulk')\n",
    "                 for hour in [' 00:00:00', ' 06:00:00', ' 12:00:00', ' 18:00:00']]\n",
    "    bulks     = []\n",
    "    for p in bulkfiles:\n",
    "        data_bulk = xr.open_dataset(p)[variables]\n",
    "        for height in range(4):\n",
    "            try:\n",
    "                data_bulk = data_bulk.isel({'height_above_ground'+str(height+1):0})\n",
    "                data_bulk = data_bulk.drop('height_above_ground'+str(height+1))\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        data_bulk = data_bulk.sortby('lat').sortby('lon').sel(\n",
    "            lat=slice(latmin,latmax), lon=slice(lonmin,lonmax)).squeeze()\n",
    "        data_bulk['time']    = pd.to_datetime(p.split('.')[-3], format='%Y%m%d%H')\n",
    "        try:\n",
    "            data_bulk = data_bulk.drop('reftime')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data_bulk = data_bulk.drop_vars('reftime')\n",
    "        except:\n",
    "            pass\n",
    "        bulks.append(data_bulk)\n",
    "    data_bulk = xr.concat(bulks,'time')\n",
    "    return data_bulk\n",
    "\n",
    "\n",
    "def get_GDASFNL_flux(idate, lonmin, lonmax, latmin, latmax, variables):\n",
    "    \"\"\"\n",
    "    Given a date and a collection of variables this function grabs\n",
    "    the GFS/FNL data from the opendap service\n",
    "\n",
    "    Args:\n",
    "        idate (_type_): _description_\n",
    "        variables (_type_, optional): _description_. Defaults to bulk_variables.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # NCEP GDAS/FNL Global Surface Flux Grids\n",
    "    fluxfiles = [get_GDASFNL_filename(idate+hour, 'flux')\n",
    "                 for hour in [' 00:00:00', ' 06:00:00', ' 12:00:00', ' 18:00:00']]\n",
    "    fluxes    = []\n",
    "    for p in fluxfiles:\n",
    "        data_flux = xr.open_dataset(p)[variables]\n",
    "        data_flux = data_flux.squeeze()\n",
    "        data_flux = data_flux.sortby('lat').sortby('lon').sel(lat=slice(latmin,latmax),\n",
    "                                                              lon=slice(lonmin,lonmax))\n",
    "        data_flux['time'] = pd.to_datetime(p.split('.')[-3], format='%Y%m%d%H')\n",
    "        try:\n",
    "            data_flux = data_flux.drop('reftime')\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data_flux = data_flux.drop_vars('reftime')\n",
    "        except:\n",
    "            pass\n",
    "        fluxes.append(data_flux)\n",
    "    data_flux = xr.concat(fluxes,'time')\n",
    "    return data_flux\n",
    "\n",
    "\n",
    "def get_GDASFNL_data(idate,\n",
    "                     lonmin=lonmin, lonmax=lonmax,\n",
    "                     latmin=latmin, latmax=latmax,\n",
    "                     bulk_variables=bulk_variables,\n",
    "                     flux_variables=flux_variables,\n",
    "                     rename_dict=fnlgfs_dictionary,\n",
    "                     outdir='./', save=False, mode='w'):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        idate (_type_): _description_\n",
    "        bulk_variables (_type_, optional): _description_. Defaults to bulk_variables.\n",
    "        flux_variables (_type_, optional): _description_. Defaults to flux_variables.\n",
    "        rename_dict (_type_, optional): _description_. Defaults to fnlgfs_dictionary.\n",
    "        outdir (str, optional): _description_. Defaults to './'.\n",
    "        save (bool, optional): _description_. Defaults to False.\n",
    "        mode (str, optional): _description_. Defaults to 'w'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    fname = outdir+'/gdas1.fnl0p25.'+idate.replace('-','').replace(' ','')+'.f00.nc'\n",
    "    if os.path.isfile(fname):\n",
    "        return xr.open_dataset(fname)\n",
    "        \n",
    "    # ---------------------------------------------------------------------------- #\n",
    "    # NCEP GDAS/FNL 0.25 Degree Global Tropospheric Analyses and Forecast Grids\n",
    "    data_bulk = get_GDASFNL_bulks(idate,\n",
    "                                  lonmin=lonmin, lonmax=lonmax,\n",
    "                                  latmin=latmin, latmax=latmax,\n",
    "                                  variables=bulk_variables)\n",
    "    # ---------------------------------------------------------------------------- #\n",
    "    # NCEP GDAS/FNL Global Surface Flux Grids\n",
    "    data_flux = get_GDASFNL_flux(idate,\n",
    "                                 lonmin=lonmin, lonmax=lonmax,\n",
    "                                 latmin=latmin, latmax=latmax,\n",
    "                                 variables=flux_variables)\n",
    "    # ---------------------------------------------------------------------------- #\n",
    "    # Regrid gaussian grid to regular and merge datasets\n",
    "    regridder = xe.Regridder(data_flux, data_bulk, 'bilinear')\n",
    "    data_flux = regridder(data_flux, keep_attrs=True)\n",
    "\n",
    "    data = xr.merge([data_flux, data_bulk])\n",
    "    data = data.rename(rename_dict)\n",
    "    if save:\n",
    "        data.to_netcdf(fname, mode=mode)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.open_dataset(get_GDASFNL_filename('2022-05-05','flux'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### GFS near real time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GFS_filename(idate, ftype):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        idate (_type_): _description_\n",
    "        ftype (_type_): _description_\n",
    "\n",
    "    Raises:\n",
    "        ValueError: _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(idate)\n",
    "    yrmonthday = date.strftime('%Y%m%d')\n",
    "    hour = date.strftime('%H')\n",
    "    url = \"http://nomads.ncep.noaa.gov:80/dods/gfs_0p25/gfs\"+yrmonthday+\"/gfs_0p25_\"+hour\n",
    "    if ftype=='forecast':\n",
    "        url = url+\"z\"\n",
    "    elif ftype=='analysis':\n",
    "        url = url+\"z_anl\"\n",
    "    else:\n",
    "        raise ValueError('ftype can only be \"forecast\" or \"analysis\"')\n",
    "    return url\n",
    "\n",
    "def get_GFS_data(idate, ftype='forecast', variables=gfs_variables,\n",
    "                outdir='./', save=False, mode='w'):\n",
    "    fname = outdir+'/gfs.0p25.'+idate.replace('-','').replace(' ','')+'.nc'\n",
    "    if os.path.isfile(fname):\n",
    "        return xr.open_dataset(fname)\n",
    "    files = [get_GFS_filename(idate+hour, ftype)\n",
    "            for hour in [' 00:00:00', ' 06:00:00', ' 12:00:00', ' 18:00:00']]\n",
    "    gfs = []\n",
    "    for p in files:\n",
    "        data = xr.open_dataset(p)\n",
    "        data = data[variables].sortby('time').isel(time=0)\n",
    "        data = data.sortby('lat').sortby('lon').sel(lat=slice(-40,-15), lon=slice(360-90,360-69)).squeeze()\n",
    "        gfs.append(data)\n",
    "    gfs = xr.concat(gfs, 'time')\n",
    "    if save:\n",
    "        gfs.to_netcdf(fname, mode=mode)\n",
    "    return gfs\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
